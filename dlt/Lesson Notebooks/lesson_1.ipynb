{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data containing pokemon details\n",
    "data = [\n",
    "    {\"id\": \"1\", \"name\": \"bulbasaur\", \"size\": {\"weight\": 6.9, \"height\": 0.7}},\n",
    "    {\"id\": \"4\", \"name\": \"charmander\", \"size\": {\"weight\": 8.5, \"height\": 0.6}},\n",
    "    {\"id\": \"25\", \"name\": \"pikachu\", \"size\": {\"weight\": 6, \"height\": 0.4}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline name, destination, and dataset name\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"quick_start\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"mydata\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You instantiate a pipeline by calling the `dlt.pipeline` function with the following arguments:\n",
    "\n",
    "* **`pipeline_name`**: This is the name you give to your pipeline. It helps you track and monitor your pipeline, and also helps to bring back its state and data structures for future runs. If you don't provide a name, dlt will use the name of the Python file you're running as the pipeline name.\n",
    "* **`destination`**: a name of the destination to which dlt will load the data. It may also be provided to the run method of the pipeline.\n",
    "* **`dataset_name`**: This is the name of the group of tables (or dataset) where your data will be sent. You can think of a dataset like a folder that holds many files, or a schema in a relational database. You can also specify this later when you run or load the pipeline. If you don't provide a name, it will default to the name of your pipeline.\n",
    "* **`dev_mode`**: If you set this to True, dlt will add a timestamp to your dataset name every time you create a pipeline. This means a new dataset will be created each time you create a pipeline.\n",
    "\n",
    "There are more arguments, but they are for advanced use, we skip it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline quick_start load step completed in 1.13 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset mydata\n",
      "The duckdb destination used duckdb:///c:\\Users\\HP\\OneDrive\\Desktop\\Data Engg\\Apache_Spark\\dlt\\quick_start.duckdb location to store data\n",
      "Load package 1740221796.9537327 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "load_info = pipeline.run(data, table_name='pokemon')\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>schema</th>\n",
       "      <th>name</th>\n",
       "      <th>column_names</th>\n",
       "      <th>column_types</th>\n",
       "      <th>temporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata</td>\n",
       "      <td>_dlt_loads</td>\n",
       "      <td>[load_id, schema_name, status, inserted_at, sc...</td>\n",
       "      <td>[VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata</td>\n",
       "      <td>_dlt_pipeline_state</td>\n",
       "      <td>[version, engine_version, pipeline_name, state...</td>\n",
       "      <td>[BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata</td>\n",
       "      <td>_dlt_version</td>\n",
       "      <td>[version, engine_version, inserted_at, schema_...</td>\n",
       "      <td>[BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quick_start</td>\n",
       "      <td>mydata</td>\n",
       "      <td>pokemon</td>\n",
       "      <td>[id, name, size__weight, size__height, _dlt_lo...</td>\n",
       "      <td>[VARCHAR, VARCHAR, DOUBLE, DOUBLE, VARCHAR, VA...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      database  schema                 name  \\\n",
       "0  quick_start  mydata           _dlt_loads   \n",
       "1  quick_start  mydata  _dlt_pipeline_state   \n",
       "2  quick_start  mydata         _dlt_version   \n",
       "3  quick_start  mydata              pokemon   \n",
       "\n",
       "                                        column_names  \\\n",
       "0  [load_id, schema_name, status, inserted_at, sc...   \n",
       "1  [version, engine_version, pipeline_name, state...   \n",
       "2  [version, engine_version, inserted_at, schema_...   \n",
       "3  [id, name, size__weight, size__height, _dlt_lo...   \n",
       "\n",
       "                                        column_types  temporary  \n",
       "0  [VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...      False  \n",
       "1  [BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...      False  \n",
       "2  [BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...      False  \n",
       "3  [VARCHAR, VARCHAR, DOUBLE, DOUBLE, VARCHAR, VA...      False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the DuckDB database\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# Set search path to the dataset\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Describe the dataset\n",
    "conn.sql(\"DESCRIBE\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used arguments for `pipeline.run`:\n",
    "\n",
    "* **`data`** (the first argument) may be a dlt source, resource, generator function, or any Iterator or Iterable (i.e., a list or the result of the map function).\n",
    "* **`write_disposition`** controls how to write data to a table. Defaults to the value \"append\".\n",
    "  * `append` will always add new data at the end of the table.\n",
    "  * `replace` will replace existing data with new data.\n",
    "  * `skip` will prevent data from loading.\n",
    "  * `merge` will deduplicate and merge data based on `primary_key` and `merge_key` hints.\n",
    "* **`table_name`**: specified in cases when the table name cannot be inferred, i.e., from the resources or name of the generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>size__weight</th>\n",
       "      <th>size__height</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bulbasaur</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1740221796.9537327</td>\n",
       "      <td>4sB3KJFnF3Hp0w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>charmander</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1740221796.9537327</td>\n",
       "      <td>fnuHa8r1tf8ROw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>pikachu</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1740221796.9537327</td>\n",
       "      <td>/4vrcF2jZGWaLQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name  size__weight  size__height        _dlt_load_id  \\\n",
       "0   1   bulbasaur           6.9           0.7  1740221796.9537327   \n",
       "1   4  charmander           8.5           0.6  1740221796.9537327   \n",
       "2  25     pikachu           6.0           0.4  1740221796.9537327   \n",
       "\n",
       "          _dlt_id  \n",
       "0  4sB3KJFnF3Hp0w  \n",
       "1  fnuHa8r1tf8ROw  \n",
       "2  /4vrcF2jZGWaLQ  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch all data from 'pokemon' as a DataFrame\n",
    "table = conn.sql(\"SELECT * FROM pokemon\").df()\n",
    "\n",
    "# Display the DataFrame\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
